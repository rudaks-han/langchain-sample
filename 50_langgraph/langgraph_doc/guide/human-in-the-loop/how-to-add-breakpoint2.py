from IPython.display import display, Image
from dotenv import load_dotenv
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph
from langgraph.graph import MessagesState, START
from langgraph.prebuilt import ToolNode

load_dotenv()


@tool
def search(query: str):
    """Call to surf the web."""
    return ["ì„œìš¸ ë‚ ì”¨ëŠ” ë§‘ì•„~ ğŸ˜ˆ."]


tools = [search]
tool_node = ToolNode(tools)

model = ChatOpenAI(model="gpt-4o-mini")
model = model.bind_tools(tools)


# ì§„í–‰ì„ ê³„ì†í• ì§€ ê²°ì •í•˜ëŠ” í•¨ìˆ˜
def should_continue(state):
    messages = state["messages"]
    last_message = messages[-1]
    # í•¨ìˆ˜ í˜¸ì¶œì´ ì—†ë‹¤ë©´ ì¤‘ë‹¨í•œë‹¤.
    if not last_message.tool_calls:
        return "end"
    # í•¨ìˆ˜ í˜¸ì¶œì´ ìˆë‹¤ë©´ ê³„ì†í•œë‹¤.
    else:
        return "continue"


# ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•œë‹¤.
def call_model(state):
    messages = state["messages"]
    response = model.invoke(messages)
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¦¬í„´í•œë‹¤. ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ëœë‹¤.
    return {"messages": [response]}


workflow = StateGraph(MessagesState)

# ë‘ ë…¸ë“œê°€ ì„œë¡œë¥¼ ìˆœí™˜í•˜ë„ë¡ ì •ì˜í•œë‹¤.
workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)

# ì‹œì‘ì ì„ 'agent'ë¡œ ì„¤ì •í•œë‹¤.
# ì´ê²ƒì€ ì´ ë…¸ë“œê°€ ì²˜ìŒìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
workflow.add_edge(START, "agent")

# ì¡°ê±´ë¶€ ì—£ì§€ë¥¼ ì¶”ê°€í•œë‹¤.
workflow.add_conditional_edges(
    # 'agent' ë…¸ë“œê°€ í˜¸ì¶œëœ í›„ì— í˜¸ì¶œë˜ëŠ” ì—£ì§€ë¥¼ ì˜ë¯¸í•œë‹¤.
    "agent",
    # ë‹¤ìŒìœ¼ë¡œ ë‹¤ìŒì— í˜¸ì¶œë  ë…¸ë“œë¥¼ ê²°ì •í•  í•¨ìˆ˜ë¥¼ ì „ë‹¬í•œë‹¤.
    should_continue,
    # ë§ˆì§€ë§‰ìœ¼ë¡œ ë§¤í•‘ì„ ì „ë‹¬í•œë‹¤.
    # í‚¤ëŠ” ë¬¸ìì—´ì´ê³ , ê°’ì€ ë‹¤ë¥¸ ë…¸ë“œë“¤ì´ë‹¤.
    # ENDëŠ” ê·¸ë˜í”„ê°€ ëë‚˜ì•¼ í•œë‹¤ëŠ” ê²ƒì„ í‘œì‹œí•˜ëŠ” íŠ¹ë³„í•œ ë…¸ë“œì´ë‹¤.
    # ì´í›„ `should_continue`ë¥¼ í˜¸ì¶œí•˜ê³ , ê·¸ ì¶œë ¥ì´ ì´ ë§¤í•‘ì˜ í‚¤ë“¤ê³¼ ì¼ì¹˜í•˜ê²Œ ëœë‹¤.
    # ë§¤ì¹­ì´ ëœë‹¤ë©´ ë…¸ë“œê°€ í˜¸ì¶œëœë‹¤.
    {
        # ë§Œì¼ `tools`ì´ë¼ë©´, ë„êµ¬ ë…¸ë“œë¥¼ í˜¸ì¶œí•œë‹¤.
        "continue": "action",
        # ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ ëë‚¸ë‹¤.
        "end": END,
    },
)

# toolsì—ì„œ agentë¡œì˜ ì¼ë°˜ ì—£ì§€ë¥¼ ì¶”ê°€í•œë‹¤.
# ì´ëŠ” toolsê°€ í˜¸ì¶œëœ í›„ì— agent ë…¸ë“œê°€ í˜¸ì¶œëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
workflow.add_edge("action", "agent")

# ë©”ëª¨ë¦¬ ì„¤ì •
memory = MemorySaver()


# interrupt_before=["action"]ë¥¼ ì¶”ê°€í•œë‹¤.
# ì´ê²ƒì€ `action` ë…¸ë“œê°€ í˜¸ì¶œë˜ê¸° ì „ì— ì¤‘ë‹¨ì ì„ ì¶”ê°€í•œë‹¤.
app = workflow.compile(checkpointer=memory, interrupt_before=["action"])

display(
    Image(
        app.get_graph().draw_mermaid_png(output_file_path="how-to-add-breakpoint2.png")
    )
)

from langchain_core.messages import HumanMessage

thread = {"configurable": {"thread_id": "3"}}
inputs = [HumanMessage(content="ì§€ê¸ˆ ì„œìš¸ ë‚ ì”¨ ê²€ìƒ‰í•´ ì¤˜")]
for event in app.stream({"messages": inputs}, thread, stream_mode="values"):
    event["messages"][-1].pretty_print()

for event in app.stream(None, thread, stream_mode="values"):
    event["messages"][-1].pretty_print()
