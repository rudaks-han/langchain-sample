from IPython.display import Image, display
from dotenv import load_dotenv
from langchain_core.tools import tool
from langgraph.graph import MessagesState, START
from langgraph.prebuilt import ToolNode

load_dotenv()


@tool
def search(query: str):
    """Call to surf the web."""
    return f"ì°¾ì•„ë´¤ìŠµë‹ˆë‹¤: {query}. ê²°ê³¼: ì„œìš¸ ë‚ ì”¨ëŠ” ì¢‹ì•„ìš”~ ğŸ˜ˆ."


tools = [search]
tool_node = ToolNode(tools)

# Set up the model
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o-mini")

from pydantic import BaseModel


class AskHuman(BaseModel):
    """Ask the human a question"""

    question: str


model = model.bind_tools(tools + [AskHuman])


def should_continue(state):
    messages = state["messages"]
    last_message = messages[-1]
    if not last_message.tool_calls:
        return "end"
    # ë„êµ¬ í˜¸ì¶œì´ ì‚¬ëŒì—ê²Œ ë¬¼ì–´ë³´ëŠ” ê²ƒì´ë©´ í•´ë‹¹ ë…¸ë“œë¥¼ ë°˜í™˜í•œë‹¤.
    # ì—¬ê¸°ì— ë¡œì§ì„ ì¶”ê°€í•˜ì—¬ ì‚¬ëŒì´ ì…ë ¥í•´ì•¼ í•˜ëŠ” ê²ƒì´ ìˆë‹¤ëŠ” ê²ƒì„ ì‹œìŠ¤í…œì— ì•Œë¦´ ìˆ˜ë„ ìˆë‹¤.
    # ì˜ˆë¥¼ ë“¤ì–´, ìŠ¬ë™ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê±°ë‚˜ ê¸°íƒ€ ë“±ë“±
    elif last_message.tool_calls[0]["name"] == "AskHuman":
        return "ask_human"
    else:
        return "continue"


def call_model(state):
    messages = state["messages"]
    response = model.invoke(messages)
    return {"messages": [response]}


# ì‚¬ëŒì—ê²Œ ë¬¼ì–´ë³´ëŠ” ê°€ì§œ ë…¸ë“œë¥¼ ì •ì˜í•œë‹¤.
def ask_human(state):
    pass


from langgraph.graph import END, StateGraph

workflow = StateGraph(MessagesState)

workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)
workflow.add_node("ask_human", ask_human)

workflow.add_edge(START, "agent")

workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        # 'tools' ë¼ë©´ ë„êµ¬ ë…¸ë“œë¥¼ í˜¸ì¶œí•œë‹¤.
        "continue": "action",
        # ì‚¬ëŒì—ê²Œ ë¬¼ì–´ë³¼ ìˆ˜ ìˆë‹¤.
        "ask_human": "ask_human",
        # ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ ì¢…ë£Œí•œë‹¤.
        "end": END,
    },
)

# toolsì—ì„œ agentë¡œ ê°€ëŠ” ì¼ë°˜ì ì¸ ì—£ì§€ë¥¼ ì¶”ê°€í•œë‹¤.
# ì´ê²ƒì€ toolsê°€ í˜¸ì¶œëœ í›„ agent ë…¸ë“œê°€ ë‹¤ìŒì— í˜¸ì¶œëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
workflow.add_edge("action", "agent")

# ì‚¬ëŒì˜ ì‘ë‹µì„ ë°›ì€ í›„ì—ëŠ” ë‹¤ì‹œ agentë¡œ ëŒì•„ê°„ë‹¤.
workflow.add_edge("ask_human", "agent")

from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()

app = workflow.compile(checkpointer=memory, interrupt_before=["ask_human"])

display(
    Image(
        app.get_graph().draw_mermaid_png(
            output_file_path="how-to-wait-graph-state-with-agent.png"
        )
    )
)

from langchain_core.messages import HumanMessage

config = {"configurable": {"thread_id": "2"}}
input_message = HumanMessage(
    content="Use the search tool to ask the user where they are, then look up the weather there"
)
for event in app.stream({"messages": [input_message]}, config, stream_mode="values"):
    event["messages"][-1].pretty_print()

tool_call_id = app.get_state(config).values["messages"][-1].tool_calls[0]["id"]

# idë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ í˜¸ì¶œì„ ë§Œë“¤ê³  ì›í•˜ëŠ” ì‘ë‹µì„ ì¶”ê°€í•œë‹¤.
tool_message = [
    {"tool_call_id": tool_call_id, "type": "tool", "content": "san francisco"}
]

# ì´ê²ƒì€ ì•„ë˜ì™€ ë™ì¼í•˜ë‹¤.
# from langchain_core.messages import ToolMessage
# tool_message = [ToolMessage(tool_call_id=tool_call_id, content="san francisco")]

# ì´ì œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•œë‹¤.
# ìš°ë¦¬ëŠ” `as_node="ask_human"`ì„ ì§€ì •í•˜ê³  ìˆë‹¤.
# ì´ê²ƒì€ ì´ ë…¸ë“œë¡œ ì´ ì—…ë°ì´íŠ¸ë¥¼ ì ìš©í•˜ê²Œ ë§Œë“¤ ê²ƒì´ë‹¤.
# ì´ê²ƒì€ ì´í›„ì— ê³„ì† ì •ìƒì ìœ¼ë¡œ ì§„í–‰ë˜ë„ë¡ ë§Œë“¤ ê²ƒì´ë‹¤.

app.update_state(config, {"messages": tool_message}, as_node="ask_human")

# ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
# ìƒíƒœì—ëŠ” í˜„ì¬ `agent` ë…¸ë“œê°€ ë‹¤ìŒì— ìˆìŒì„ ë³¼ ìˆ˜ ìˆë‹¤.
# ì´ê²ƒì€ ê·¸ë˜í”„ë¥¼ ì–´ë–»ê²Œ ì •ì˜í–ˆëŠ”ì§€ì— ë”°ë¼ ê²°ì •ëœë‹¤.
# ìš°ë¦¬ëŠ” ë°©ê¸ˆ íŠ¸ë¦¬ê±°í•œ `ask_human` ë…¸ë“œ ì´í›„ì—
# `agent` ë…¸ë“œë¡œ ê°€ëŠ” ì—£ì§€ê°€ ìˆë‹¤.
print(app.get_state(config).next)

for event in app.stream(None, config, stream_mode="values"):
    event["messages"][-1].pretty_print()
